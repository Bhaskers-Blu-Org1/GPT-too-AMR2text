# training
batch_size: 3
max_norm: 3
n_epochs: 1
seed: 42
learning: ['sl']  # sl - suvervised learning

# optimization
learning_rate: 5.0e-5
warmup_steps: 120
adam_epsilon: 1.0e-8
weight_decay: 0.0
gamma: 1
gradient_accumulation_steps: 8
max_input_length: 300
max_num_examples: 80000 # 75K is the corpus size

# sampling
top_k: 0
top_p: 0.9 # nucleus sampling
temperature: 1
max_length: 50

# misc
fp16: '' # Set to O0, O1, O2 or O3 for fp16 training
logging: 100
re_tokenize: False
traintype: 'train'
rewardtype: ['ce']
device: 'cuda'
checkpoint: './checkpoint'

# dataset
dataset_type: ['dusquad'] # ['natural_questions', 'squad', 'drop', 'cardie']
dataset_path: 'DATA'
dataset_cache: 'DATA/cache/'
